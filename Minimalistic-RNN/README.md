Minimal character-based language model learning with RNNs.

Inspired from Andrej Karpathy's min-char-rnn:
   
    [CS231N Winter 2016 Lecture 11](https://www.youtube.com/watch?v=yCC09vCHzF8&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&index=10)
    
    [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

    [Min-Char-RNN by Andrej-Karpathy](https://gist.github.com/karpathy/d4dee566867f8291f086)

The original structure of the code is retained.

This is not a very good model. This is just for understanding the nuts and bolts of RNN.
A better model is LSTM Networks. An excellent read for LSTM can be found below:

    http://colah.github.io/posts/2015-08-Understanding-LSTMs/